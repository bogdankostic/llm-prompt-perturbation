,model,original,syntactic,score_difference,rank_original,rank_syntactic
0,GPT-5-Nano,37.4415,36.829,0.6124999999999972,5.0,7.0
1,GPT-5-mini,39.638999999999996,38.084,1.5549999999999926,2.0,2.0
2,GPT-4.1-Nano,34.124,33.539,0.5850000000000009,15.0,15.0
3,GPT-4.1-mini,35.9915,35.0665,0.9250000000000043,10.0,10.0
4,GPT-OSS-120b,39.829,39.174,0.6550000000000011,1.0,1.0
5,GPT-OSS-20b,37.744,37.7165,0.027499999999996305,4.0,3.0
6,Llama-3.3-70B-Instruct,32.699,32.3065,0.3924999999999983,17.0,16.0
7,Llama-3.1-8B-Instruct,29.8005,29.8045,-0.004000000000001336,19.0,19.0
8,Llama-3.2-3B-Instruct,26.5815,27.354,-0.7725000000000009,21.0,20.0
9,Llama-3.2-1B-Instruct,22.194,21.834,0.35999999999999943,22.0,22.0
10,gemini-2.5-flash,38.053,36.918,1.134999999999998,3.0,5.0
11,gemini-2.5-flash-lite,36.0365,34.489,1.5474999999999994,9.0,12.0
12,gemma-3-27b-it,35.4015,35.4615,-0.060000000000002274,11.0,9.0
13,gemma-3-12b-it,35.1415,35.8365,-0.6950000000000003,12.0,8.0
14,gemma-3-4b-it,32.723,32.147999999999996,0.5750000000000028,16.0,17.0
15,gemma-3-1b-it,26.886499999999998,26.019000000000002,0.8674999999999962,20.0,21.0
16,gemma-3-270m-it,15.7065,14.4365,1.2699999999999996,23.0,23.0
17,Mistral-Large-Instruct-2411,34.854,33.7565,1.0974999999999966,13.0,14.0
18,Mistral-Small-3.2-24B-Instruct-2506,36.778999999999996,35.036500000000004,1.7424999999999926,7.0,11.0
19,Ministral-8B-Instruct-2410,30.794,29.874,0.9200000000000017,18.0,18.0
20,Qwen3-235B-A22B-Instruct-2507,37.2665,37.214,0.05250000000000199,6.0,4.0
21,Qwen3-30B-A3B-Instruct-2507,36.653999999999996,36.884,-0.23000000000000398,8.0,6.0
22,Qwen3-4B-Instruct-2507,34.223,34.353,-0.13000000000000256,14.0,13.0
