,model,original,lexical,score_difference,rank_original,rank_lexical
0,GPT-5-Nano,37.4415,35.5065,1.9349999999999952,5.0,8.0
1,GPT-5-mini,39.638999999999996,37.494,2.144999999999996,2.0,3.0
2,GPT-4.1-Nano,34.124,33.409,0.7150000000000034,15.0,13.0
3,GPT-4.1-mini,35.9915,35.648,0.3434999999999988,10.0,7.0
4,GPT-OSS-120b,39.829,39.364,0.4650000000000034,1.0,1.0
5,GPT-OSS-20b,37.744,36.0665,1.677500000000002,4.0,6.0
6,Llama-3.3-70B-Instruct,32.699,32.208999999999996,0.490000000000002,17.0,16.0
7,Llama-3.1-8B-Instruct,29.8005,28.354,1.4465000000000003,19.0,19.0
8,Llama-3.2-3B-Instruct,26.5815,25.2775,1.3039999999999985,21.0,21.0
9,Llama-3.2-1B-Instruct,22.194,19.709,2.4849999999999994,22.0,22.0
10,gemini-2.5-flash,38.053,37.9415,0.11149999999999949,3.0,2.0
11,gemini-2.5-flash-lite,36.0365,34.9615,1.0749999999999957,9.0,10.0
12,gemma-3-27b-it,35.4015,34.2005,1.2010000000000005,11.0,12.0
13,gemma-3-12b-it,35.1415,34.414,0.7274999999999991,12.0,11.0
14,gemma-3-4b-it,32.723,31.514,1.2089999999999996,16.0,17.0
15,gemma-3-1b-it,26.886499999999998,26.169,0.7174999999999976,20.0,20.0
16,gemma-3-270m-it,15.7065,11.699,4.0075,23.0,23.0
17,Mistral-Large-Instruct-2411,34.854,32.4665,2.3874999999999957,13.0,15.0
18,Mistral-Small-3.2-24B-Instruct-2506,36.778999999999996,35.2715,1.5074999999999932,7.0,9.0
19,Ministral-8B-Instruct-2410,30.794,29.296499999999998,1.4975000000000023,18.0,18.0
20,Qwen3-235B-A22B-Instruct-2507,37.2665,37.019,0.24750000000000227,6.0,4.0
21,Qwen3-30B-A3B-Instruct-2507,36.653999999999996,36.583,0.07099999999999795,8.0,5.0
22,Qwen3-4B-Instruct-2507,34.223,33.1965,1.0264999999999986,14.0,14.0
